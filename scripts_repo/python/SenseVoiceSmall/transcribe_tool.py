#!/usr/bin/env python3
# -*- encoding: utf-8 -*-

import argparse
import json
import sys
import os
from pathlib import Path
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
from model import SenseVoiceSmall
FUNASR_AVAILABLE = True
# å°è¯•å¯¼å…¥SenseVoiceç›¸å…³ä¾èµ–

# è¿™æ˜¯å¯ç¼–è¾‘çš„ Python æ¨¡æ¿ç¤ºä¾‹
# çº¦å®šï¼šæä¾› ARGS_MAP å¹¶æ”¯æŒ --_sys_get_schema è¾“å‡ºå‚æ•°å®šä¹‰

ARGS_MAP = {
    "audio": {
        "flag": "--audio", 
        "type": "file", 
        "required": True, 
        "help": "éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (æ”¯æŒ .mp3, .wav, .m4a, .flac ç­‰æ ¼å¼)"
    },
    "language": {
        "flag": "--language", 
        "type": "str", 
        "required": False, 
        "default": "auto",
        "help": "æŒ‡å®šè¯­è¨€ (auto, zh, en, yue, ja, ko)ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹"
    },
    "use_itn": {
        "flag": "--use-itn", 
        "type": "bool", 
        "required": False, 
        "default": True,
        "help": "å¯ç”¨ITNï¼ˆåæ–‡æœ¬æ ‡å‡†åŒ–ï¼‰ï¼ŒåŒ…å«æ ‡ç‚¹å’Œæ•°å­—æ ¼å¼åŒ–"
    },
    "output_timestamp": {
        "flag": "--output-timestamp", 
        "type": "bool", 
        "required": False, 
        "default": False,
        "help": "è¾“å‡ºè¯çº§åˆ«æ—¶é—´æˆ³"
    },
    "output_file": {
        "flag": "--output-file", 
        "type": "str", 
        "required": False, 
        "help": "è¾“å‡ºç»“æœåˆ°æ–‡ä»¶è·¯å¾„"
    },
    "device": {
        "flag": "--device", 
        "type": "str", 
        "required": False, 
        "default": "cpu",
        "help": "è®¡ç®—è®¾å¤‡ (cpu, cuda:0, cuda:1)"
    }
}


def get_schema():
    """è¿”å›å‚æ•°å®šä¹‰çš„JSONæ ¼å¼"""
    return json.dumps(ARGS_MAP, ensure_ascii=False)


def validate_audio_file(audio_path):
    """éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ”¯æŒ"""
    if not os.path.exists(audio_path):
        return False, f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"
    
    supported_formats = ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac']
    file_ext = Path(audio_path).suffix.lower()
    
    if file_ext not in supported_formats:
        return False, f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {file_ext}ï¼Œæ”¯æŒçš„æ ¼å¼: {', '.join(supported_formats)}"
    
    return True, ""


def transcribe_audio(audio_path, language="auto", use_itn=True, output_timestamp=False, device="cpu"):
    """ä½¿ç”¨SenseVoiceè¿›è¡ŒéŸ³é¢‘è½¬å½•"""
    
    # æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨
    if not FUNASR_AVAILABLE:
        return {
            "success": False,
            "error": f"ç¼ºå°‘å¿…è¦ä¾èµ–: {IMPORT_ERROR}",
            "code": 500
        }
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        model_dir = "iic/SenseVoiceSmall"
        model = AutoModel(
            model=model_dir,
            trust_remote_code=True,
            remote_code="./model.py",
            vad_model="fsmn-vad",
            vad_kwargs={"max_single_segment_time": 30000},
            device=device,
        )
        
        # è¿›è¡Œè¯­éŸ³è¯†åˆ«
        res = model.generate(
            input=audio_path,
            cache={},
            language=language,
            use_itn=use_itn,
            batch_size_s=60,
            merge_vad=True,
            merge_length_s=15,
        )
        
        if not res or len(res) == 0:
            return {
                "success": False,
                "error": "è½¬å½•å¤±è´¥æˆ–æ— ç»“æœ",
                "code": 400
            }
        
        # å¤„ç†ç»“æœ
        result_data = {
            "success": True,
            "text": rich_transcription_postprocess(res[0]["text"]),
            "code": 200
        }
        
        # æ·»åŠ å…ƒæ•°æ®
        metadata = {}
        if "language" in res[0]:
            metadata["detected_language"] = res[0]["language"]
        
        if "emo_result" in res[0]:
            metadata["emotion_analysis"] = res[0]["emo_result"]
            
        if "event_result" in res[0]:
            metadata["event_detection"] = res[0]["event_result"]
        
        # æ–‡ä»¶ä¿¡æ¯
        metadata["file_size_mb"] = round(os.path.getsize(audio_path) / 1024 / 1024, 2)
        metadata["file_path"] = audio_path
        
        if metadata:
            result_data["metadata"] = metadata
        
        # æ—¶é—´æˆ³ä¿¡æ¯
        if output_timestamp:
            try:
                # ä½¿ç”¨ç›´æ¥æ¨¡å‹æ¨ç†è·å–æ—¶é—´æˆ³
                m, kwargs = SenseVoiceSmall.from_pretrained(model=model_dir, device=device)
                m.eval()
                
                timestamp_res = m.inference(
                    data_in=audio_path,
                    language=language,
                    use_itn=use_itn,
                    ban_emo_unk=False,
                    output_timestamp=True,
                    **kwargs,
                )
                
                if timestamp_res and len(timestamp_res) > 0 and len(timestamp_res[0]) > 0:
                    result_data["timestamps"] = timestamp_res[0][0].get("timestamp", [])
                    
            except Exception as e:
                # æ—¶é—´æˆ³æå–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                print(f"è­¦å‘Š: æ—¶é—´æˆ³æå–å¤±è´¥: {e}")
        
        return result_data
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è½¬å½•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}",
            "code": 500
        }


def main():
    parser = argparse.ArgumentParser(description="SenseVoiceéŸ³é¢‘è½¬å½•å·¥å…·")
    
    for key, cfg in ARGS_MAP.items():
        arg_kwargs = {
            "required": cfg.get("required", False),
            "help": cfg.get("help", "")
        }
        
        # å¤„ç†å¸ƒå°”ç±»å‹å‚æ•°
        if cfg["type"] == "bool":
            if cfg.get("default", False):
                arg_kwargs["action"] = "store_false"
                # å°†flagæ”¹ä¸º--no-flagæ ¼å¼
                flag = cfg["flag"].replace("--", "--no-")
            else:
                arg_kwargs["action"] = "store_true"
                flag = cfg["flag"]
            
            if cfg.get("default") is not None:
                arg_kwargs["default"] = cfg["default"]
            
            parser.add_argument(flag, **arg_kwargs)
        else:
            parser.add_argument(cfg["flag"], **arg_kwargs)

    if len(sys.argv) > 1 and sys.argv[1] == "--_sys_get_schema":
        print(get_schema())
        sys.exit(0)

    args = parser.parse_args()
    
    # è·å–å‚æ•°
    audio_path = getattr(args, 'audio')
    language = getattr(args, 'language', 'auto')
    use_itn = getattr(args, 'use_itn', True)
    output_timestamp = getattr(args, 'output_timestamp', False)
    output_file = getattr(args, 'output_file', None)
    device = getattr(args, 'device', 'cpu')
    
    # éªŒè¯éŸ³é¢‘æ–‡ä»¶
    is_valid, error_msg = validate_audio_file(audio_path)
    if not is_valid:
        result = {
            "success": False,
            "error": error_msg,
            "code": 400
        }
        print(json.dumps(result, ensure_ascii=False))
        sys.exit(1)
    
    # æ‰§è¡Œè½¬å½•
    print(f"ğŸµ å¼€å§‹è½¬å½•éŸ³é¢‘: {audio_path}")
    result = transcribe_audio(audio_path, language, use_itn, output_timestamp, device)
    
    # è¾“å‡ºç»“æœ
    if result.get("success"):
        print("âœ… è½¬å½•æˆåŠŸï¼")
        
        # è¾“å‡ºåˆ°æ–‡ä»¶
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ§åˆ¶å°è¾“å‡ºä¸»è¦ç»“æœ
        print("\nğŸ“ è½¬å½•ç»“æœ:")
        print("=" * 60)
        print(result.get("text", ""))
        print("=" * 60)
        
        # æ˜¾ç¤ºå…ƒæ•°æ®
        if "metadata" in result:
            print("\nğŸ“Š å…ƒæ•°æ®:")
            for key, value in result["metadata"].items():
                print(f"   {key}: {value}")
    
    else:
        print(f"âŒ è½¬å½•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    # è¾“å‡ºå®Œæ•´JSONç»“æœ
    print(json.dumps(result, ensure_ascii=False))


if __name__ == "__main__":
    main()
